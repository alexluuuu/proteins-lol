{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial CNN \n",
    "Alex Lu (alu2)\n",
    "November 16, 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import pandas as pd \n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils \n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to extend torch dataset in order to use torch dataloader. Implementation based off of https://pytorch.org/tutorials/beginner/data_loading_tutorial.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanProteinDataset(Dataset):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, labels_csv, root_dir, transform=None):\n",
    "        self.label_names = {\n",
    "            0:  \"Nucleoplasm\",  \n",
    "            1:  \"Nuclear membrane\",   \n",
    "            2:  \"Nucleoli\",   \n",
    "            3:  \"Nucleoli fibrillar center\",   \n",
    "            4:  \"Nuclear speckles\",\n",
    "            5:  \"Nuclear bodies\",   \n",
    "            6:  \"Endoplasmic reticulum\",   \n",
    "            7:  \"Golgi apparatus\",   \n",
    "            8:  \"Peroxisomes\",   \n",
    "            9:  \"Endosomes\",   \n",
    "            10:  \"Lysosomes\",   \n",
    "            11:  \"Intermediate filaments\",   \n",
    "            12:  \"Actin filaments\",   \n",
    "            13:  \"Focal adhesion sites\",   \n",
    "            14:  \"Microtubules\",   \n",
    "            15:  \"Microtubule ends\",   \n",
    "            16:  \"Cytokinetic bridge\",   \n",
    "            17:  \"Mitotic spindle\",   \n",
    "            18:  \"Microtubule organizing center\",   \n",
    "            19:  \"Centrosome\",   \n",
    "            20:  \"Lipid droplets\",   \n",
    "            21:  \"Plasma membrane\",   \n",
    "            22:  \"Cell junctions\",   \n",
    "            23:  \"Mitochondria\",   \n",
    "            24:  \"Aggresome\",   \n",
    "            25:  \"Cytosol\",   \n",
    "            26:  \"Cytoplasmic bodies\",   \n",
    "            27:  \"Rods & rings\"\n",
    "        }\n",
    "\n",
    "        self.labels_df = pd.read_csv(labels_csv)\n",
    "        for _, row in self.labels_df.iterrows():\n",
    "            labels = np.array(row.Target.split(\" \")).astype(np.int)\n",
    "            row.Target = np.array([1 if i in labels else 0 for i in range(28)])\n",
    "            \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.raw_h = 512\n",
    "        self.raw_w = 512\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "#        image_base = os.path.join(self.root_dir, self.labels_df.iloc[idx, 0])\n",
    "        image_stack = self._load_image(self.labels_df.iloc[idx, 0])\n",
    "        \n",
    "        sample = {'stack': image_stack, 'labels': self.labels_df['Target'].iloc[idx]}\n",
    "        if self.transform: \n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    def _load_image(self, image_id, factor = 1):\n",
    "        image_stack = np.zeros((4,self.raw_w,self.raw_h))\n",
    "        image_stack[0,:,:] = io.imread(self.root_dir + image_id + \"_green\" + \".png\")\n",
    "        image_stack[1,:,:] = io.imread(self.root_dir + image_id + \"_red\" + \".png\")\n",
    "        image_stack[2,:,:] = io.imread(self.root_dir + image_id + \"_blue\" + \".png\")\n",
    "        image_stack[3,:,:] = io.imread(self.root_dir + image_id + \"_yellow\" + \".png\")\n",
    "\n",
    "        if factor != 1:\n",
    "            image_scaled = np.zeros(shape=(4, int(self.raw_w*factor), int(self.raw_h*factor)))\n",
    "            image_scaled[0,:,:] = rescale(images[0,:,:], factor)\n",
    "            image_scaled[1,:,:] = rescale(images[1,:,:], factor)\n",
    "            image_scaled[2,:,:] = rescale(images[2,:,:], factor)\n",
    "            image_scaled[3,:,:] = rescale(images[3,:,:], factor)\n",
    "            return image_scaled\n",
    "\n",
    "        return image_stack \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, scaled_dims):\n",
    "        self.scaled_dims = scaled_dims\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        stack_raw = sample['stack']\n",
    "        \n",
    "        stack_scaled = np.zeros(shape = (4, self.scaled_dims[0], self.scaled_dims[1]))\n",
    "        stack_scaled[0,:,:] = transform.resize(stack_raw[0, :, :], self.scaled_dims)\n",
    "        stack_scaled[1,:,:] = transform.resize(stack_raw[1, :, :], self.scaled_dims)\n",
    "        stack_scaled[2,:,:] = transform.resize(stack_raw[2, :, :], self.scaled_dims)\n",
    "        stack_scaled[3,:,:] = transform.resize(stack_raw[3, :, :], self.scaled_dims)\n",
    "        \n",
    "        return {'stack': stack_scaled, 'labels':sample['labels']}\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        temp = sample['stack']/255.0\n",
    "        totensor = transforms.ToTensor()\n",
    "        sample['stack'] = totensor(temp.transpose((1, 2, 0)))\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "data = HumanProteinDataset(labels_csv = './data/train.csv',\n",
    "                          root_dir = './data/train/',\n",
    "                          transform = transforms.Compose([\n",
    "                                                          Rescale((256, 256)),\n",
    "                                                          ToTensor()\n",
    "                         ]))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    sample = data[i]\n",
    "    #print sample\n",
    "    print sum(sample['labels'])\n",
    "    if i == 2:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(labels_csv = './data/train.csv', root_dir = './data/train/',):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    data = HumanProteinDataset(labels_csv, root_dir, transform=transforms.Compose([\n",
    "                                                          Rescale((256, 256)),\n",
    "                                                          ToTensor()\n",
    "                         ]))\n",
    "    indices = np.arange(len(data))\n",
    "    indices_train = np.random.choice(indices, size=int(.75*len(data)), replace=False)\n",
    "    indices_test = list(set(indices) - set(indices_train))\n",
    "    \n",
    "    sampler_train = SubsetRandomSampler(indices_train)\n",
    "    sampler_test = SubsetRandomSampler(indices_test)\n",
    "    \n",
    "    dataloader_train = DataLoader(data, batch_size=5, sampler=sampler_train, num_workers=4)\n",
    "    dataloader_test = DataLoader(data, batch_size=5, sampler=sampler_test, num_workers=4)\n",
    "    \n",
    "    return (dataloader_train, dataloader_test)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([5, 4, 256, 256]) torch.Size([5, 28])\n",
      "1 torch.Size([5, 4, 256, 256]) torch.Size([5, 28])\n",
      "2 torch.Size([5, 4, 256, 256]) torch.Size([5, 28])\n",
      "3 torch.Size([5, 4, 256, 256]) torch.Size([5, 28])\n",
      "4 torch.Size([5, 4, 256, 256]) torch.Size([5, 28])\n",
      "5 torch.Size([5, 4, 256, 256]) torch.Size([5, 28])\n",
      "6 torch.Size([5, 4, 256, 256]) torch.Size([5, 28])\n",
      "7 torch.Size([5, 4, 256, 256]) torch.Size([5, 28])\n",
      "8 torch.Size([5, 4, 256, 256]) torch.Size([5, 28])\n",
      "9 torch.Size([5, 4, 256, 256]) torch.Size([5, 28])\n",
      "10 torch.Size([5, 4, 256, 256]) torch.Size([5, 28])\n",
      "11 torch.Size([5, 4, 256, 256]) torch.Size([5, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-11:\n",
      "    img = t(img)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-74-54e956ce1603>\", line 59, in __getitem__\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    sample = self.transform(sample)\n",
      "    self.run()\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/torchvision-0.2.1-py2.7.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-82-1859bdc826de>\", line 15, in __call__\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    stack_scaled[3,:,:] = transform.resize(stack_raw[3, :, :], self.scaled_dims)\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/skimage/transform/_warps.py\", line 135, in resize\n",
      "  File \"<ipython-input-74-54e956ce1603>\", line 55, in __getitem__\n",
      "    image_stack = self._load_image(self.labels_df.iloc[idx, 0])\n",
      "  File \"<ipython-input-74-54e956ce1603>\", line 65, in _load_image\n",
      "    image_stack[0,:,:] = io.imread(self.root_dir + image_id + \"_green\" + \".png\")\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/skimage/io/_plugins/pil_plugin.py\", line 35, in imread\n",
      "    with open(fname, 'rb') as f:\n",
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-74-54e956ce1603>\", line 55, in __getitem__\n",
      "    image_stack = self._load_image(self.labels_df.iloc[idx, 0])\n",
      "  File \"<ipython-input-74-54e956ce1603>\", line 65, in _load_image\n",
      "    image_stack[0,:,:] = io.imread(self.root_dir + image_id + \"_green\" + \".png\")\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/skimage/io/_plugins/pil_plugin.py\", line 35, in imread\n",
      "    with open(fname, 'rb') as f:\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Process Process-12:\n",
      "    preserve_range=preserve_range)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/skimage/transform/_warps.py\", line 769, in warp\n",
      "    order=order, mode=mode, cval=cval)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"skimage/transform/_warps_cy.pyx\", line 131, in skimage.transform._warps_cy._warp_fast (skimage/transform/_warps_cy.c:2637)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/inspect.py\", line 1051, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/inspect.py\", line 1015, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/linecache.py\", line 41, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/linecache.py\", line 131, in updatecache\n",
      "    with open(fullname, 'rU') as fp:\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 13506) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self.run()\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Users/alex/miniconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2893\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alex/miniconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1826\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alex/miniconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1411\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alex/miniconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1319\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m             )\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alex/miniconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/numpy/core/numeric.py\", line 424, in asarray\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-74-54e956ce1603>\", line 55, in __getitem__\n",
      "    image_stack = self._load_image(self.labels_df.iloc[idx, 0])\n",
      "  File \"<ipython-input-74-54e956ce1603>\", line 66, in _load_image\n",
      "    image_stack[1,:,:] = io.imread(self.root_dir + image_id + \"_red\" + \".png\")\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/skimage/io/_plugins/pil_plugin.py\", line 35, in imread\n",
      "    with open(fname, 'rb') as f:\n",
      "KeyboardInterrupt\n",
      "    def asarray(a, dtype=None, order=None):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(get_data_loaders()[0]):\n",
    "    print i_batch, sample_batched['stack'].size(), sample_batched['labels'].size()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.W = self.H = 256\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(4, 8, 5, 1, 2), # input_channels, output_channels, kernele_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(      #input: 4xWxH\n",
    "            nn.Conv2d(8,16,5,1,2),        # input_channels, output_channels, kernel_size, stride, padding   \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2), #output: 16xW/4xH/4\n",
    "        )\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.out1 = nn.Linear( int(16 * self.W/4 * self.H/4), 900)\n",
    "        self.out2 = nn.Linear(900, 28)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.drop_out(x)\n",
    "        output = self.out1(output)\n",
    "        output = self.out2(output)\n",
    "        return output\n",
    "    \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model, epochs=10, criterion=nn.BCEWithLogitsLoss(reduction='sum'), optimizer=None):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    dataloader_train = get_data_loaders()[0]\n",
    "    \n",
    "    if optimizer is None:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=.04, betas=(.9, .99))\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print \"training with device:\" + str(device)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i_batch, sample_batch in enumerate(dataloader_train):\n",
    "            stacks, labels = sample_batch['stack'], sample_batch['labels']\n",
    "            \n",
    "            stacks, labels = stacks.to(device, dtype=torch.float), labels.to(device, dtype=torch.float)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(stacks)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i_batch % 10 == 9:\n",
    "                print '\\n[%d, %5d] loss: %.3f'%(epoch+1, i_batch+1, loss.item())\n",
    "                running_loss = 0.0\n",
    "    \n",
    "    print 'Finished training!'\n",
    "\n",
    "    \n",
    "def run_model(model, batch):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    stacks = batch.to(device, dtype=torch.float)\n",
    "    output = model(stacks).cpu()\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with device:cpu\n",
      "\n",
      "[1,    10] loss: 20.938\n",
      "\n",
      "[1,    20] loss: 37.021\n",
      "\n",
      "[1,    30] loss: 30.009\n",
      "\n",
      "[1,    40] loss: 25.317\n",
      "\n",
      "[1,    50] loss: 24.674\n",
      "\n",
      "[1,    60] loss: 24.706\n",
      "\n",
      "[1,    70] loss: 30.546\n",
      "\n",
      "[1,    80] loss: 25.941\n",
      "\n",
      "[1,    90] loss: 26.016\n",
      "\n",
      "[1,   100] loss: 23.802\n",
      "\n",
      "[1,   110] loss: 20.225\n",
      "\n",
      "[1,   120] loss: 27.812\n",
      "\n",
      "[1,   130] loss: 24.283\n",
      "\n",
      "[1,   140] loss: 31.988\n",
      "\n",
      "[1,   150] loss: 20.849\n",
      "\n",
      "[1,   160] loss: 23.717\n",
      "\n",
      "[1,   170] loss: 27.216\n",
      "\n",
      "[1,   180] loss: 23.780\n",
      "\n",
      "[1,   190] loss: 30.063\n",
      "\n",
      "[1,   200] loss: 29.082\n",
      "\n",
      "[1,   210] loss: 27.042\n",
      "\n",
      "[1,   220] loss: 24.108\n",
      "\n",
      "[1,   230] loss: 25.897\n",
      "\n",
      "[1,   240] loss: 29.025\n",
      "\n",
      "[1,   250] loss: 29.922\n",
      "\n",
      "[1,   260] loss: 30.639\n",
      "\n",
      "[1,   270] loss: 30.384\n",
      "\n",
      "[1,   280] loss: 24.121\n",
      "\n",
      "[1,   290] loss: 28.079\n",
      "\n",
      "[1,   300] loss: 18.939\n",
      "\n",
      "[1,   310] loss: 22.572\n",
      "\n",
      "[1,   320] loss: 24.826\n",
      "\n",
      "[1,   330] loss: 22.755\n",
      "\n",
      "[1,   340] loss: 27.670\n",
      "\n",
      "[1,   350] loss: 24.157\n",
      "\n",
      "[1,   360] loss: 22.456\n",
      "\n",
      "[1,   370] loss: 26.361\n",
      "\n",
      "[1,   380] loss: 32.346\n",
      "\n",
      "[1,   390] loss: 24.605\n",
      "\n",
      "[1,   400] loss: 21.440\n",
      "\n",
      "[1,   410] loss: 23.913\n",
      "\n",
      "[1,   420] loss: 31.305\n",
      "\n",
      "[1,   430] loss: 24.485\n",
      "\n",
      "[1,   440] loss: 24.234\n",
      "\n",
      "[1,   450] loss: 29.577\n",
      "\n",
      "[1,   460] loss: 24.850\n",
      "\n",
      "[1,   470] loss: 26.541\n",
      "\n",
      "[1,   480] loss: 22.017\n",
      "\n",
      "[1,   490] loss: 22.721\n",
      "\n",
      "[1,   500] loss: 22.804\n",
      "\n",
      "[1,   510] loss: 22.316\n",
      "\n",
      "[1,   520] loss: 28.201\n",
      "\n",
      "[1,   530] loss: 22.390\n",
      "\n",
      "[1,   540] loss: 22.093\n",
      "\n",
      "[1,   550] loss: 23.698\n",
      "\n",
      "[1,   560] loss: 35.860\n",
      "\n",
      "[1,   570] loss: 27.885\n",
      "\n",
      "[1,   580] loss: 19.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-36:\n",
      "Process Process-34:\n",
      "Process Process-35:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/queues.py\", line 131, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/queues.py\", line 131, in get\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/queues.py\", line 131, in get\n",
      "    if not self._poll(timeout):\n",
      "Process Process-33:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "    if not self._poll(timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-74-54e956ce1603>\", line 55, in __getitem__\n",
      "    image_stack = self._load_image(self.labels_df.iloc[idx, 0])\n",
      "  File \"<ipython-input-74-54e956ce1603>\", line 66, in _load_image\n",
      "    image_stack[1,:,:] = io.imread(self.root_dir + image_id + \"_red\" + \".png\")\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/alex/miniconda2/lib/python2.7/site-packages/skimage/io/_plugins/pil_plugin.py\", line 35, in imread\n",
      "    with open(fname, 'rb') as f:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-4fbeff8876e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-3ce9a04eb42f>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(model, epochs, criterion, optimizer)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi_batch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alex/miniconda2/lib/python2.7/site-packages/torch/optim/adam.pyc\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "cnn = CNN()\n",
    "cnn.apply(init_weights)\n",
    "\n",
    "Train(cnn, epochs=5,  criterion=nn.BCEWithLogitsLoss(reduction='sum'), optimizer = optim.Adam(cnn.parameters(), lr=0.001, betas=(0.9, 0.99)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_targets(row, label_names, full):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "\n",
    "    row.Target = np.array(row.Target.split(\" \")).astype(np.int)\n",
    "    if full:\n",
    "        for num in row.Target:\n",
    "            name = label_names[int(num)]\n",
    "            row.loc[name] = 1\n",
    "    return row\n",
    "\n",
    "def read_labels(labels_csv):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    print 'reading the label csv'\n",
    "\n",
    "    label_names = {\n",
    "        0:  \"Nucleoplasm\",  \n",
    "        1:  \"Nuclear membrane\",   \n",
    "        2:  \"Nucleoli\",   \n",
    "        3:  \"Nucleoli fibrillar center\",   \n",
    "        4:  \"Nuclear speckles\",\n",
    "        5:  \"Nuclear bodies\",   \n",
    "        6:  \"Endoplasmic reticulum\",   \n",
    "        7:  \"Golgi apparatus\",   \n",
    "        8:  \"Peroxisomes\",   \n",
    "        9:  \"Endosomes\",   \n",
    "        10:  \"Lysosomes\",   \n",
    "        11:  \"Intermediate filaments\",   \n",
    "        12:  \"Actin filaments\",   \n",
    "        13:  \"Focal adhesion sites\",   \n",
    "        14:  \"Microtubules\",   \n",
    "        15:  \"Microtubule ends\",   \n",
    "        16:  \"Cytokinetic bridge\",   \n",
    "        17:  \"Mitotic spindle\",   \n",
    "        18:  \"Microtubule organizing center\",   \n",
    "        19:  \"Centrosome\",   \n",
    "        20:  \"Lipid droplets\",   \n",
    "        21:  \"Plasma membrane\",   \n",
    "        22:  \"Cell junctions\",   \n",
    "        23:  \"Mitochondria\",   \n",
    "        24:  \"Aggresome\",   \n",
    "        25:  \"Cytosol\",   \n",
    "        26:  \"Cytoplasmic bodies\",   \n",
    "        27:  \"Rods & rings\"\n",
    "    }\n",
    "\n",
    "    df = pd.read_csv(labels_csv)\n",
    "\n",
    "    full = False\n",
    "    if full:\n",
    "        for key in label_names.keys():\n",
    "            df[label_names[key]] = 0\n",
    "\n",
    "        df = df.apply(fill_targets, axis=1, args=((label_names, full)))\n",
    "\n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            row.Target = np.array(row.Target.split(\" \")).astype(np.int)\n",
    "    return (df, df['Id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading the label csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>[16, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>[7, 1, 2, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>[18]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id        Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0       [16, 0]\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  [7, 1, 2, 0]\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0           [5]\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0           [1]\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0          [18]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, ids = read_labels(\"./data/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "255.0\n"
     ]
    }
   ],
   "source": [
    "def load_image(image_id, basepath = \"./data/train/\", factor = 1):\n",
    "    image_stack = np.zeros((4,512,512))\n",
    "    image_stack[0,:,:] = io.imread(basepath + image_id + \"_green\" + \".png\", )\n",
    "    image_stack[1,:,:] = io.imread(basepath + image_id + \"_red\" + \".png\")\n",
    "    image_stack[2,:,:] = io.imread(basepath + image_id + \"_blue\" + \".png\")\n",
    "    image_stack[3,:,:] = io.imread(basepath + image_id + \"_yellow\" + \".png\")\n",
    "\n",
    "    if factor != 1:\n",
    "        image_scaled = np.zeros(shape=(4, int(512*factor), int(512*factor)))\n",
    "        image_scaled[0,:,:] = rescale(images[0,:,:], factor)\n",
    "        image_scaled[1,:,:] = rescale(images[1,:,:], factor)\n",
    "        image_scaled[2,:,:] = rescale(images[2,:,:], factor)\n",
    "        image_scaled[3,:,:] = rescale(images[3,:,:], factor)\n",
    "        return image_scaled\n",
    "\n",
    "    return image_stack \n",
    "\n",
    "x = load_image(\"00070df0-bbc3-11e8-b2bc-ac1f6b6435d0\")\n",
    "print np.min(x)\n",
    "print np.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "labels = [0, 27, 5]\n",
    "temp = [1 if i in labels else 0 for i in range(28)]\n",
    "print temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
